{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analysis of Estimation Errors in Portfolio Optimization**\n",
    "\n",
    "## This notebook analyzes the impact of estimation errors in means, variances, and covariances on portfolio optimization results. We'll use historical data to create a base portfolio and then simulate various types of estimation errors to understand their effects on portfolio performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.random import default_rng\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import custom modules\n",
    "from src.data_management import DataManager\n",
    "from src.portfolio_optimizer import PortfolioParameters, create_base_portfolio\n",
    "from src.error_analysis import ErrorAnalysisConfig, run_error_analysis\n",
    "from src.visualization import PortfolioVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection and Processing\n",
    "First, we'll define our universe of stocks (DJIA constituents) and randomly select 10 of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Stocks:\n",
      "- AMGN\n",
      "- AXP\n",
      "- CRM\n",
      "- GS\n",
      "- JNJ\n",
      "- KO\n",
      "- MMM\n",
      "- NKE\n",
      "- TRV\n",
      "- WMT\n"
     ]
    }
   ],
   "source": [
    "djia_constituents = [\n",
    "    'AAPL',  # Apple\n",
    "    'AMGN',  # Amgen\n",
    "    'AXP',   # American Express\n",
    "    'BA',    # Boeing\n",
    "    'CAT',   # Caterpillar\n",
    "    'CRM',   # Salesforce\n",
    "    'CSCO',  # Cisco\n",
    "    'CVX',   # Chevron\n",
    "    'DIS',   # Disney\n",
    "    'DOW',   # Dow Inc.\n",
    "    'GS',    # Goldman Sachs\n",
    "    'HD',    # Home Depot\n",
    "    'HON',   # Honeywell\n",
    "    'IBM',   # IBM\n",
    "    'INTC',  # Intel\n",
    "    'JNJ',   # Johnson & Johnson\n",
    "    'JPM',   # JPMorgan Chase\n",
    "    'KO',    # Coca-Cola\n",
    "    'MCD',   # McDonald's\n",
    "    'MMM',   # 3M\n",
    "    'MRK',   # Merck\n",
    "    'MSFT',  # Microsoft\n",
    "    'NKE',   # Nike\n",
    "    'PG',    # Procter & Gamble\n",
    "    'TRV',   # Travelers\n",
    "    'UNH',   # UnitedHealth\n",
    "    'V',     # Visa\n",
    "    'VZ',    # Verizon\n",
    "    'WBA',   # Walgreens Boots Alliance\n",
    "    'WMT',   # Walmart\n",
    "]\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "rng = default_rng(42)\n",
    "\n",
    "# Randomly select 10 stocks\n",
    "selected_symbols = sorted(rng.choice(djia_constituents, size=10, replace=False))\n",
    "\n",
    "print(\"Selected Stocks:\")\n",
    "for symbol in selected_symbols:\n",
    "    print(f\"- {symbol}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:31:09,134 - src.data_management - INFO - Initialized DataManager with 10 symbols\n",
      "2024-11-29 14:31:09,229 - src.data_management - INFO - Data loaded successfully for 10 symbols\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Portfolio Components Statistics:\n",
      "\n",
      "AMGN:\n",
      "  Expected Monthly Return: 2.2277%\n",
      "  Monthly Volatility: 7.9929%\n",
      "\n",
      "AXP:\n",
      "  Expected Monthly Return: 2.5788%\n",
      "  Monthly Volatility: 8.9089%\n",
      "\n",
      "CRM:\n",
      "  Expected Monthly Return: 1.1137%\n",
      "  Monthly Volatility: 5.0717%\n",
      "\n",
      "GS:\n",
      "  Expected Monthly Return: 1.8014%\n",
      "  Monthly Volatility: 6.8561%\n",
      "\n",
      "JNJ:\n",
      "  Expected Monthly Return: 0.6672%\n",
      "  Monthly Volatility: 4.5168%\n",
      "\n",
      "KO:\n",
      "  Expected Monthly Return: 1.6570%\n",
      "  Monthly Volatility: 7.1277%\n",
      "\n",
      "MMM:\n",
      "  Expected Monthly Return: 2.1688%\n",
      "  Monthly Volatility: 9.7777%\n",
      "\n",
      "NKE:\n",
      "  Expected Monthly Return: 2.1990%\n",
      "  Monthly Volatility: 6.3406%\n",
      "\n",
      "TRV:\n",
      "  Expected Monthly Return: 5.7350%\n",
      "  Monthly Volatility: 13.5089%\n",
      "\n",
      "WMT:\n",
      "  Expected Monthly Return: 1.8031%\n",
      "  Monthly Volatility: 5.7076%\n",
      "\n",
      "Data Range:\n",
      "First data point: 2014-12-01\n",
      "Last data point: 2024-11-27\n"
     ]
    }
   ],
   "source": [
    "# Initialize DataManager\n",
    "data_manager = DataManager(\n",
    "    symbols=selected_symbols,\n",
    "    start_date='2014-01-01',  # Using 5 years of data\n",
    "    end_date='2023-12-31',\n",
    "    data_dir='../data'\n",
    ")\n",
    "\n",
    "# Process data\n",
    "statistics = data_manager.process_all()\n",
    "\n",
    "# Print basic statistics\n",
    "print(\"\\nPortfolio Components Statistics:\")\n",
    "for i, symbol in enumerate(selected_symbols):\n",
    "    print(f\"\\n{symbol}:\")\n",
    "    print(f\"  Expected Monthly Return: {statistics['expected_returns'][i]:.4%}\")\n",
    "    print(f\"  Monthly Volatility: {np.sqrt(statistics['covariance_matrix'][i,i]):.4%}\")\n",
    "\n",
    "# Print data range\n",
    "print(\"\\nData Range:\")\n",
    "print(f\"First data point: {data_manager.prices.index[0].strftime('%Y-%m-%d')}\")\n",
    "print(f\"Last data point: {data_manager.prices.index[-1].strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Base Portfolio Optimization\n",
    "\n",
    "Now we'll create a base optimal portfolio using the true parameters (historical estimates).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base Portfolio Allocation:\n",
      "TRV: 40.00%\n",
      "AXP: 28.07%\n",
      "WMT: 24.78%\n",
      "NKE: 7.15%\n",
      "\n",
      "Portfolio Characteristics:\n",
      "Expected Monthly Return: 3.62%\n",
      "Monthly Portfolio Risk: 7.70%\n",
      "Active Positions (>1%): 4\n",
      "Annualized Sharpe Ratio (Rf=0): 1.63\n"
     ]
    }
   ],
   "source": [
    "# Create base optimal portfolio\n",
    "risk_tolerance = 50  # Moderate risk tolerance\n",
    "optimal_weights, base_optimizer = create_base_portfolio(\n",
    "    expected_returns=statistics['expected_returns'],\n",
    "    covariance_matrix=statistics['covariance_matrix'],\n",
    "    risk_tolerance=risk_tolerance\n",
    ")\n",
    "\n",
    "# Print base portfolio characteristics\n",
    "print(\"\\nBase Portfolio Allocation:\")\n",
    "selected_weights = [(symbol, weight) for symbol, weight in zip(selected_symbols, optimal_weights) \n",
    "                   if weight > 0.01]  # Only show positions > 1%\n",
    "selected_weights.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for symbol, weight in selected_weights:\n",
    "    print(f\"{symbol}: {weight:.2%}\")\n",
    "\n",
    "expected_return = np.dot(optimal_weights, statistics['expected_returns'])\n",
    "portfolio_risk = np.sqrt(optimal_weights @ statistics['covariance_matrix'] @ optimal_weights)\n",
    "\n",
    "print(f\"\\nPortfolio Characteristics:\")\n",
    "print(f\"Expected Monthly Return: {expected_return:.2%}\")\n",
    "print(f\"Monthly Portfolio Risk: {portfolio_risk:.2%}\")\n",
    "print(f\"Active Positions (>1%): {len(selected_weights)}\")\n",
    "print(f\"Annualized Sharpe Ratio (Rf=0): {(expected_return * 12) / (portfolio_risk * np.sqrt(12)):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Error Analysis Configuration\n",
    "\n",
    "We'll configure the error analysis parameters to study how different types and magnitudes of estimation errors affect portfolio performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:31:22,838 - src.error_analysis - INFO - Starting analysis with 100 iterations per combination\n",
      "2024-11-29 14:31:22,840 - src.error_analysis - INFO - Total parameter combinations: 36\n",
      "2024-11-29 14:31:22,842 - src.error_analysis - INFO - Total simulations to run: 3600\n",
      "2024-11-29 14:31:22,845 - src.error_analysis - INFO - Processing combination 1/36: means, k=0.05, rt=25\n",
      "2024-11-29 14:31:22,846 - src.error_analysis - INFO - Processing combination 2/36: means, k=0.05, rt=50\n",
      "2024-11-29 14:31:22,848 - src.error_analysis - INFO - Processing combination 3/36: means, k=0.05, rt=75\n",
      "2024-11-29 14:31:22,850 - src.error_analysis - INFO - Processing combination 4/36: means, k=0.1, rt=25\n",
      "2024-11-29 14:31:22,853 - src.error_analysis - INFO - Processing combination 5/36: means, k=0.1, rt=50\n",
      "2024-11-29 14:31:22,855 - src.error_analysis - INFO - Processing combination 6/36: means, k=0.1, rt=75\n",
      "2024-11-29 14:31:22,857 - src.error_analysis - INFO - Processing combination 7/36: means, k=0.15, rt=25\n",
      "2024-11-29 14:31:22,859 - src.error_analysis - INFO - Processing combination 8/36: means, k=0.15, rt=50\n",
      "2024-11-29 14:31:22,860 - src.error_analysis - INFO - Processing combination 9/36: means, k=0.15, rt=75\n",
      "2024-11-29 14:31:22,862 - src.error_analysis - INFO - Processing combination 10/36: means, k=0.2, rt=25\n",
      "2024-11-29 14:31:22,867 - src.error_analysis - INFO - Processing combination 11/36: means, k=0.2, rt=50\n",
      "2024-11-29 14:31:22,870 - src.error_analysis - INFO - Processing combination 12/36: means, k=0.2, rt=75\n",
      "2024-11-29 14:31:22,872 - src.error_analysis - INFO - Processing combination 13/36: variances, k=0.05, rt=25\n",
      "2024-11-29 14:31:22,873 - src.error_analysis - INFO - Processing combination 14/36: variances, k=0.05, rt=50\n",
      "2024-11-29 14:31:22,875 - src.error_analysis - INFO - Processing combination 15/36: variances, k=0.05, rt=75\n",
      "2024-11-29 14:31:22,876 - src.error_analysis - INFO - Processing combination 16/36: variances, k=0.1, rt=25\n",
      "2024-11-29 14:31:22,878 - src.error_analysis - INFO - Processing combination 17/36: variances, k=0.1, rt=50\n",
      "2024-11-29 14:31:22,880 - src.error_analysis - INFO - Processing combination 18/36: variances, k=0.1, rt=75\n",
      "2024-11-29 14:31:22,881 - src.error_analysis - INFO - Processing combination 19/36: variances, k=0.15, rt=25\n",
      "2024-11-29 14:31:22,883 - src.error_analysis - INFO - Processing combination 20/36: variances, k=0.15, rt=50\n",
      "2024-11-29 14:31:22,884 - src.error_analysis - INFO - Processing combination 21/36: variances, k=0.15, rt=75\n",
      "2024-11-29 14:31:22,889 - src.error_analysis - INFO - Processing combination 22/36: variances, k=0.2, rt=25\n",
      "2024-11-29 14:31:22,890 - src.error_analysis - INFO - Processing combination 23/36: variances, k=0.2, rt=50\n",
      "2024-11-29 14:31:22,892 - src.error_analysis - INFO - Processing combination 24/36: variances, k=0.2, rt=75\n",
      "2024-11-29 14:31:22,894 - src.error_analysis - INFO - Processing combination 25/36: covariances, k=0.05, rt=25\n",
      "2024-11-29 14:31:22,895 - src.error_analysis - INFO - Processing combination 26/36: covariances, k=0.05, rt=50\n",
      "2024-11-29 14:31:22,897 - src.error_analysis - INFO - Processing combination 27/36: covariances, k=0.05, rt=75\n",
      "2024-11-29 14:31:22,898 - src.error_analysis - INFO - Processing combination 28/36: covariances, k=0.1, rt=25\n",
      "2024-11-29 14:31:22,900 - src.error_analysis - INFO - Processing combination 29/36: covariances, k=0.1, rt=50\n",
      "2024-11-29 14:31:22,903 - src.error_analysis - INFO - Processing combination 30/36: covariances, k=0.1, rt=75\n",
      "2024-11-29 14:31:22,905 - src.error_analysis - INFO - Processing combination 31/36: covariances, k=0.15, rt=25\n",
      "2024-11-29 14:31:22,907 - src.error_analysis - INFO - Processing combination 32/36: covariances, k=0.15, rt=50\n",
      "2024-11-29 14:31:22,911 - src.error_analysis - INFO - Processing combination 33/36: covariances, k=0.15, rt=75\n",
      "2024-11-29 14:31:22,913 - src.error_analysis - INFO - Processing combination 34/36: covariances, k=0.2, rt=25\n",
      "2024-11-29 14:31:22,915 - src.error_analysis - INFO - Processing combination 35/36: covariances, k=0.2, rt=50\n",
      "2024-11-29 14:31:22,917 - src.error_analysis - INFO - Processing combination 36/36: covariances, k=0.2, rt=75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting error analysis...\n",
      "Total combinations to process: 36\n",
      "Iterations per combination: 100\n",
      "Using 4 CPU cores\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configure error analysis\n",
    "config = ErrorAnalysisConfig(\n",
    "    n_iterations=5,  # Drásticamente reducido para prueba\n",
    "    error_magnitudes=np.array([0.10]),  # Solo una magnitud\n",
    "    risk_tolerances=np.array([50]),  # Solo un nivel de riesgo\n",
    "    n_jobs=1,  # Un solo proceso\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(\"Starting error analysis...\")\n",
    "print(f\"Total combinations to process: {len(config.error_magnitudes) * len(config.risk_tolerances) * 3}\")\n",
    "print(f\"Iterations per combination: {config.n_iterations}\")\n",
    "print(f\"Using {config.n_jobs} CPU cores\\n\")\n",
    "\n",
    "# Run error analysis with progress tracking\n",
    "results = run_error_analysis(\n",
    "    expected_returns=statistics['expected_returns'],\n",
    "    covariance_matrix=statistics['covariance_matrix'],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Print completion message\n",
    "print(\"\\nError analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics\n",
    "print(\"\\nError Analysis Summary:\")\n",
    "print(\"\\nMean Cash Equivalent Loss (CEL) by Error Type and Magnitude:\")\n",
    "cel_summary = results.xs(('cel', 'mean'), level=1, axis=1).groupby('error_type').mean()\n",
    "print(cel_summary.round(4))\n",
    "\n",
    "print(\"\\nMean Weight Difference by Error Type and Magnitude:\")\n",
    "weight_diff_summary = results.xs(('mean_weight_diff', 'mean'), level=1, axis=1).groupby('error_type').mean()\n",
    "print(weight_diff_summary.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization of Results\n",
    "Let's create various visualizations to better understand the impact of estimation errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualizer\n",
    "visualizer = PortfolioVisualizer(figsize=(12, 8))\n",
    "\n",
    "# Create and save all visualizations\n",
    "visualizer.create_analysis_dashboard(results, output_dir='../figures')\n",
    "\n",
    "# Display key plots inline\n",
    "visualizer.plot_cel_heatmap(results)\n",
    "plt.show()\n",
    "\n",
    "visualizer.plot_cel_confidence_bands(results)\n",
    "plt.show()\n",
    "\n",
    "visualizer.plot_risk_return_scatter(results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysis of Results\n",
    "Let's analyze the key findings from our error analysis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate detailed summary statistics\n",
    "summary_stats = pd.DataFrame({\n",
    "    'Error Type': results.index.get_level_values('error_type'),\n",
    "    'Error Magnitude': results.index.get_level_values('error_magnitude'),\n",
    "    'Risk Tolerance': results.index.get_level_values('risk_tolerance'),\n",
    "    'Mean CEL': results[('cel', 'mean')],\n",
    "    'Max CEL': results[('cel', 'max')],\n",
    "    'Mean Weight Diff': results[('mean_weight_diff', 'mean')],\n",
    "    'Return Difference': results[('suboptimal_return', 'mean')] - results[('optimal_return', 'mean')],\n",
    "    'Risk Difference': results[('suboptimal_risk', 'mean')] - results[('optimal_risk', 'mean')]\n",
    "}).round(4)\n",
    "\n",
    "# Group by error type and magnitude\n",
    "grouped_stats = summary_stats.groupby(['Error Type', 'Error Magnitude']).mean()\n",
    "print(\"\\nDetailed Summary Statistics:\")\n",
    "print(grouped_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading_research_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
